---
title: "CherAnalysis"
output:
  html_document:
    code_folding: hide
    theme: yeti
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
  word_document:
    toc: yes
    toc_depth: '3'
---

```{r setup, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
library(broom)
library(broom.mixed)
library(reshape2)

## Stats
library(lme4)      # Mixed models
library(lmerTest)
library(modeest)   # Mode estimation
library(vcd)       # Fit of count data
library(sjPlot)
library(pscl)
library(readr)

## Graphics
library(ggplot2)
library(ggthemes)
library(ggExtra)
library(ggsci)
library(scales)
library(viridis)

## tables
library(kableExtra)
library(xtable)
```


# Load

Load all subjects

```{r}
bdata <- read_csv("../gambling_clean_data.csv", show_col_types = F)
```

Load the model assignments

```{r}
assignments <- read_csv("../LL_model2.csv", show_col_types = FALSE)
```

Double check we have the right data:

```{r}
ggplot(assignments, aes(x=best.model, fill=best.model)) +
  stat_count() + 
  ylim(c(0, 200)) +  
  stat_count(binwidth=1, 
             geom="text", 
             aes(label=..count..), vjust=-1.5) +
  scale_fill_d3() +
  theme_minimal()
```
## Parameter Differences Between the Two Groups

We are going to calculate two measure of relative model efficiency, a learning rate difference ($\alpha - d$) and a temperature difference (procedural - declarative).

```{r}
assignments <- assignments %>%
  mutate(TempDiff = proc.temp - decl.temp) %>%
  mutate(LearnDiff = alpha + decay) %>%
  mutate(Procedural = if_else(best.model=="Procedural", 1, 0))
```

Now let's plot the differences in temperatures across both groups:

```{r}
ggplot(assignments, aes(x=best.model, y=TempDiff, fill=best.model)) +
  geom_boxplot() +
  theme_minimal() +
  ggtitle("Differences In Temperature Across Groups") +
  xlab("Procedural Temp - Declarative Temp") +
  scale_fill_d3()
```
A logistic model can successfully account for this:

```{r}
mod <- glm(Procedural ~ TempDiff, 
           family="binomial",
           #weights=abs(diff.LL),
           data=assignments)

tab_model(mod)
```

as well as a t-test:

```{r}
t.test(TempDiff ~ best.model, assignments, paired=F) %>%
  tidy() %>%
  kable() %>%
  kable_styling(bootstrap_options=c("striped", "hover"))
```

It is difficult to conceptualize alpha vs. decay, but we can plot them:

```{r}
ggplot(assignments, aes(x=(decay*decl.temp), y=alpha/proc.temp, col=best.model, size=abs(diff.LL))) +
  geom_point() +
  theme_minimal() +
  ggtitle("Differences In Learning / Decay Rates Across Groups") +
  scale_fill_d3()
```

# Behavioral Analysis

First we need to merge the behavioral and assignment data

```{r}
full <- full_join(bdata, assignments, by="HCPID")
```

# Group Differences in Response Switch

```{r}
bytrial <- full %>%
  group_by(HCPID, TrialType) %>%
  filter(!is.na(ResponseSwitch)) %>%
  summarise(ResponseSwitch = mean(ResponseSwitch),
            RT = mean(RT),
            Model=mlv(best.model),
            deltaLL = mean(diff.LL)) %>%
  mutate(TrialType = recode(TrialType, Reward = "Win", Punishment = "Loss", Neutral = "Neutral"))
```

And now, let's visualize

```{r, fig.width=5, fig.height=5}
ggplot(bytrial, aes(x=TrialType, y=ResponseSwitch, col=Model, fill=Model)) +
  stat_summary(geom="point", fun.data="mean_se", size=3) +
  stat_summary(geom="ribbon", fun.data = mean_se, alpha=0.5) +
  stat_summary(geom="errorbar", fun.data = mean_se, width=0.1) +
  stat_summary(geom="line", aes(group=Model), fun.data="mean_se") +
  coord_cartesian(ylim=c(0, .75)) +
  ylab("Probability of Changing Response") +
  xlab("Trial Type") +
  ggtitle("Group Differences in Responses") +
  scale_color_d3() +
  scale_fill_d3() +
  theme_minimal() +
  theme(legend.position = "bottom")

ggsave("responseswitch.png", dpi=72)
```

The analysis reveal a main effect of Model (Group):

```{r}
mod_feedback <- glmer(ResponseSwitch ~ best.model *  TrialType + (1|HCPID) + (0 + TrialType|HCPID),  
                      family="binomial",
                      weights=abs(diff.LL), 
                      data=filter(full, !is.na(ResponseSwitch)))

mod_feedback %>%
  tidy() %>%
  kable() %>%
  kable_styling(bootstrap_options=c("striped", "hover"))

tab_model(mod_feedback)
```


# Group Differences in Persistance

Now, let's look at the data by block:

```{r, fig.width=5, fig.height=5}
byblock <- full %>%
  group_by(HCPID, BlockTypeCoded) %>%
  summarise(Persistance = mean(ConsecSameResp),
            MaxPersistance = max(ConsecSameResp),
            RT = mean(RT),
            Model=mlv(best.model),
            deltaLL = mean(diff.LL)) %>%
  rename(Block = BlockTypeCoded) %>%
  mutate(Block = recode(Block, MostlyReward = "Mostly Wins", MostlyPunishment = "Mostly Losses")) 
```

This is a visualization of the mean persistance by block and model.

```{r}
ggplot(byblock, aes(x=Block, y=Persistance, col=Model, fill=Model)) +
  stat_summary(geom="point", fun.data="mean_se", size=3) +
  stat_summary(geom="ribbon", fun.data = "mean_se", alpha=0.5) +
  stat_summary(geom="errorbar", fun.data = "mean_se", width=0.1) +
  stat_summary(geom="line", aes(group=Model), fun.data="mean_se") +
  xlab("Block Type") +
  ylab("Max Consecutive Identical Responses") +
  ggtitle("Persistence by Model and Block Type") +
  scale_color_d3() +
  scale_fill_d3() +
  theme_minimal()

ggsave("persistance.png", dpi=72)
```

To analyze this, we will use generalized linear model with a Poisson distribution. The choice of a Poisson distribution is given by the fact that the distribution of longest consecutive streaks (persistance) should obey a Poisson. Just in case, here is the actual distribution.

```{r}
ggplot(byblock, aes(x=MaxPersistance, fill=Model)) +
  geom_histogram(col="white", alpha=0.5, position = "identity", bins=15) +
  scale_fill_d3() +
  theme_minimal()

ggplot(byblock, aes(x=MaxPersistance, fill=Model)) +
  geom_density(col="white", alpha=0.5, position = "identity", bw=4) +
  scale_fill_d3() +
  theme_minimal()
```



We first fit a Poisson model

```{r}

mod1 <- glmer(MaxPersistance ~ Model * Block + (1|HCPID),  
              family="poisson", 
              weights=abs(byblock$deltaLL), 
              data=byblock)

mod1 %>%
  tidy() %>%
  kable() %>%
  kable_styling(bootstrap_options=c("striped", "hover"))

tab_model(mod1)
```

It is possible to conceptualize the Max Persistance count as a Negative binomial

```{r}
mod2 <- MASS::glm.nb(MaxPersistance ~ Model * Block,  
                     weights=abs(byblock$deltaLL),
                     data=byblock)

mod2 %>%
  tidy() %>%
  kable() %>%
  kable_styling(bootstrap_options=c("striped", "hover"))

tab_model(mod2)

```

Neither one first the data _too_ well, TBH, but they do fit better than a normal distribution.

```{r}
gf <- goodfit(byblock$MaxPersistance, type= "nbinomial",method= "ML")
summary(gf)
plot(gf,main="Count data vs Negative Binomial distribution")

gf <- goodfit(byblock$MaxPersistance, type= "poisson",method= "ML")
summary(gf)
plot(gf,main="Count data vs Poisson distribution")
```


# Group Differences in Response Times.

Then, we look at differences in RTs

```{r, fig.width=5, fig.height=5}
ggplot(byblock, aes(x=Block, y=RT, col=Model, group=Model)) +
  stat_summary(geom="point", fun.data="mean_se", size=3) +
  stat_summary(geom="errorbar", fun.data = "mean_se", width=0.1) +
  stat_summary(geom="line", aes(group=Model), fun.data="mean_se") +
  ylab("Response Times (ms)") +
  ggtitle("Group Differences in Response Times") +
  scale_color_d3() +
  theme_minimal() +
  theme(legend.position = "bottom")

ggsave("responsetimes.png", dpi=72)
```


This time, a linear mixed model does not reveal any effect, besides the effect of the win.

```{r}
mod3 <- glmer(log(RT) ~ Model * Block + (1|HCPID), 
              family="Gamma", 
              weights = abs(deltaLL), 
              byblock)
tab_model(mod3)
```


```{r, fig.width=6, fig.height=2}  
model <- read_csv("../LL_model2.csv")
model %>%pivot_longer(cols=c("alpha", "proc.temp", "decay", "decl.temp", "diff.LL"), names_to = "Parameter", values_to = "Values") -> lmodel

lmodel %>%
  mutate(Parameter = replace(Parameter, Parameter == "diff.LL", "W")) %>%
  mutate(Parameter = replace(Parameter, Parameter == "decay", "d")) %>%
  mutate(Parameter = replace(Parameter, Parameter == "proc.temp", "T")) %>%
  mutate(Parameter = replace(Parameter, Parameter == "decl.temp", "S")) -> lmodel

ggplot(filter(lmodel, HCPID %in% c("156233_fnca", "108828_fnca", "105014_fnca", "163129_fnca")), 
       aes(x=Parameter, y = Values, fill=HCPID)) +
 geom_col(alpha=0.5, width=0.5) +
  #geom_line(aes(group=HCPID)) +
 coord_polar() +
  facet_wrap(~HCPID, ncol = 4) +
 theme_minimal() +
  xlab("") +
  ylab("") +
  theme(legend.position = "")
```