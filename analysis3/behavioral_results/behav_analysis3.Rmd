---
title: "CherAnalysis"
output:
  html_document:
    code_folding: hide
    theme: yeti
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
  word_document:
    toc: yes
    toc_depth: '3'
---

```{r setup, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
library(broom)
library(broom.mixed)
library(reshape2)

## Stats
library(lme4)      # Mixed models
library(lmerTest)
library(modeest)   # Mode estimation
library(vcd)       # Fit of count data
library(sjPlot)
library(pscl)
library(readr)

## Graphics
library(ggplot2)
library(ggthemes)
library(ggExtra)
library(ggsci)
library(scales)
library(viridis)

## tables
library(kableExtra)
library(xtable)
```


# Load

Load all subjects

```{r}
bdata <- read_csv("../gambling_clean_data.csv", show_col_types = F)
```

Load the model assignments

```{r}
assignments <- read_csv("../LL_model2.csv", show_col_types = FALSE)
```

Double check we have the right data:

```{r}
ggplot(assignments, aes(x=best.model, fill=best.model)) +
  stat_count() + 
  ylim(c(0, 200)) +  
  stat_count(binwidth=1, 
             geom="text", 
             aes(label=..count..), vjust=-1.5) +
  scale_fill_d3() +
  theme_minimal()
```
## Parameter Differences Between the Two Groups

We are going to calculate two measure of relative model efficiency, a learning rate difference ($\alpha - d$) and a temperature difference (procedural - declarative).

```{r}
assignments <- assignments %>%
  mutate(TempDiff = proc.temp - decl.temp) %>%
  mutate(LearnDiff = alpha + decay) %>%
  mutate(Procedural = if_else(best.model=="Procedural", 1, 0))
```

Now let's plot the differences in temperatures across both groups:

```{r}
ggplot(assignments, aes(x=best.model, y=TempDiff, fill=best.model)) +
  geom_boxplot() +
  theme_minimal() +
  ggtitle("Differences In Temperature Across Groups") +
  xlab("Procedural Temp - Declarative Temp") +
  scale_fill_d3()
```
A logistic model can successfully account for this:

```{r}
mod <- glm(Procedural ~ TempDiff, 
           family="binomial",
           #weights=abs(diff.LL),
           data=assignments)

tab_model(mod)
```

as well as a t-test:

```{r}
t.test(TempDiff ~ best.model, assignments, paired=F) %>%
  tidy() %>%
  kable() %>%
  kable_styling(bootstrap_options=c("striped", "hover"))
```

It is difficult to conceptualize alpha vs. decay, but we can plot them:

```{r}
ggplot(assignments, aes(x=(decay*decl.temp), y=alpha/proc.temp, col=best.model, size=abs(diff.LL))) +
  geom_point() +
  theme_minimal() +
  ggtitle("Differences In Learning / Decay Rates Across Groups") +
  scale_fill_d3()
```

# Behavioral Analysis

First we need to merge the behavioral and assignment data

```{r}
full <- full_join(bdata, assignments, by="HCPID")
```

# Group Differences in Response Switch

```{r}
bytrial <- full %>%
  group_by(HCPID, TrialType) %>%
  filter(!is.na(ResponseSwitch)) %>%
  summarise(ResponseSwitch = mean(ResponseSwitch),
            RT = mean(RT),
            Model=mlv(best.model),
            deltaLL = mean(diff.LL)) %>%
  mutate(TrialType = recode(TrialType, Reward = "Win", Punishment = "Loss", Neutral = "Neutral"))
```

And now, let's visualize

```{r, fig.width=5, fig.height=5}
ggplot(bytrial, aes(x=TrialType, y=ResponseSwitch, col=Model, fill=Model)) +
  stat_summary(geom="point", fun.data="mean_se", size=3) +
  stat_summary(geom="ribbon", fun.data = mean_se, alpha=0.5) +
  stat_summary(geom="errorbar", fun.data = mean_se, width=0.1) +
  stat_summary(geom="line", aes(group=Model), fun.data="mean_se") +
  coord_cartesian(ylim=c(0, .75)) +
  ylab("Probability of Changing Response") +
  xlab("Trial Type") +
  ggtitle("Group Differences in Responses") +
  scale_color_d3() +
  scale_fill_d3() +
  theme_minimal() +
  theme(legend.position = "bottom")

ggsave("responseswitch.png", dpi=72)
```

The analysis reveal a main effect of Model (Group):

```{r}

mlm_feedback_I <- glmer(ResponseSwitch ~ best.model *  TrialType + (1|HCPID),  
                         family="binomial",
                         weights=abs(diff.LL), 
                         data=filter(full, !is.na(ResponseSwitch)))

mlm_feedback_IS <- glmer(ResponseSwitch ~ best.model *  TrialType + (1|HCPID) + (0 + TrialType|HCPID),  
                         family="binomial",
                         weights=abs(diff.LL), 
                         data=filter(full, !is.na(ResponseSwitch)))

anova(mlm_feedback_I, mlm_feedback_IS)

mlm_feedback_IS %>%
  tidy() %>%
  kable() %>%
  kable_styling(bootstrap_options=c("striped", "hover"))

tab_model(mlm_feedback_IS)
```
